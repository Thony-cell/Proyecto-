import re
from bs4 import BeautifulSoup
import matplotlib.pyplot as plt
import numpy as np
from PIL import Image
from wordcloud import WordCloud, ImageColorGenerator, STOPWORDS
import requests
from io import BytesIO
from bs4 import BeautifulSoup
import requests
import pandas as pan
from os import path
from matplotlib.pyplot import imread
import matplotlib.pyplot as plt
from PIL import Image
import sys, os, webbrowser, platform
 
import time
from time import sleep
from sys import stdout
 
import numpy as np
from wordcloud import WordCloud, ImageColorGenerator
from PIL import Image
import requests
from io import BytesIO
 
 
from sys import stdout
 
 
RED, WHITE, CYAN, GREEN, END = '\033[91m', '\33[46m', '\033[36m', '\033[1;32m', '\033[0m'
 
 
for i in range(101):
        time.sleep(0.01)
        stdout.write("\r{0}[{3}*{0}]{2} Iniciando Programa Por Favor Espere... %d%%".format(GREEN, END, CYAN, RED, WHITE) % i)
        stdout.flush()
        time.sleep(0.02)
 
id = input("\n\n[*] Digite el ID del usuario para mostrar la nube de palabras: \n    ")
print("\n")
for i in range(101):
        time.sleep(0.01)
        stdout.write("\r{0}[{3}*{0}]{2} Abriendo Base De Datos De StackOverFlow... %d%%".format(GREEN, END, CYAN, RED, WHITE) % i)
        stdout.flush()
        time.sleep(0.02)
 
for i in range(101):
        time.sleep(0.01)
        stdout.write("\r{0}[{3}*{0}]{2} Cargando Usuarios De StackOverFlow... %d%%".format(GREEN, END, CYAN, RED, WHITE) % i)
        stdout.flush()
        time.sleep(0.02)
 
print (f"\n\n[*] Buscando Usuario << {id} >> En StackOverFlow Data Base Por Favor Espere")
for i in range(101):
        time.sleep(0.01)
        stdout.write("\r{0}[{3}*{0}]{2} %d%%".format(GREEN, END, CYAN, RED, WHITE) % i)
        stdout.flush()
        time.sleep(0.02)
 
if id.isdigit () != True:
  print ("\n\nDato no valido.")
else:
  url = 'https://es.stackoverflow.com/users/' + id + "/?tab=tags"
  page = requests.get (url)   # requests chequea que el url funciona
 
 
page= requests.get(url)
 
soup = BeautifulSoup (page.content, "html.parser") # BeautifulSoup analiza el htlm
lbls = soup.find_all ('a', class_='post-tag') # lbls = etiquetas de usuario
labels = list ()
 
for i in lbls:
    labels.append(i.text)
print (labels)
 
 
 
 
#unique_string=(" ").join(labels)
 
 
url = "https://i.imgur.com/28vAIdX.jpg"
clr = "black"
cw = 0
 
 
unique_string = (" ").join (labels)
print("\n")
response = requests.get (url)
creation = np.asarray (Image.open (BytesIO (response.content)))  #np transforma la imagen en un array
wordcloud = WordCloud (background_color = clr, mask=creation, contour_width = cw, regexp=r"\S[\S']+").generate (unique_string)
colors = ImageColorGenerator (creation)
wordcloud.recolor (color_func = colors)
plt.figure (figsize = (15, 8))
plt.imshow (wordcloud)
plt.axis ("off")
plt.show ()
plt.close ()
